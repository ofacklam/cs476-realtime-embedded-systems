{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Subset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = transforms.Compose([ToTensor(), transforms.Resize(16)])\n",
    "mnist_train = datasets.MNIST('mnist_data/', download=True, train=True, transform=tf)\n",
    "mnist_test = datasets.MNIST('mnist_data/', download=True, train=False, transform=tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [0, 1, 2, 3, 4]\n",
    "train_indices = [i for i, label in enumerate(mnist_train.targets) if label in targets]\n",
    "mnist_train_s = Subset(mnist_train, train_indices)\n",
    "test_indices = [i for i, label in enumerate(mnist_test.targets) if label in targets]\n",
    "mnist_test_s = Subset(mnist_test, test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torch.utils.data.DataLoader(mnist_train_s, batch_size=256, shuffle=True)\n",
    "test_set = torch.utils.data.DataLoader(mnist_test_s, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 16\n",
    "hidden_size = 16\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(img_size*img_size, hidden_size, bias=False),\n",
    "            nn.ReLU(),\n",
    "            #nn.Linear(hidden_size, hidden_size),\n",
    "            #nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 5, bias=False),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=16, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=16, out_features=5, bias=False)\n",
      "    (3): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#model = NeuralNetwork().to(device)\n",
    "model = torch.load('model_tiny.pth', map_location=torch.device(device))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(tqdm(dataloader)):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #if batch % 100 == 0:\n",
    "        #    loss, current = loss.item(), batch * len(X)\n",
    "        #    print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_set, model, loss_fn, optimizer)\n",
    "    test_loop(test_set, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model_tiny.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, labs = next(iter(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 16, 16]) torch.Size([256])\n",
      "tensor(2) tensor(2)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "idx = random.randint(0, len(imgs))\n",
    "print(imgs.shape, labs.shape)\n",
    "plt.imshow(imgs[idx].squeeze())\n",
    "pred = model(imgs[idx].to(device))\n",
    "print(torch.argmax(pred.cpu()), labs[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = transforms.Compose([\n",
    "    ToTensor(), \n",
    "    transforms.CenterCrop(240), \n",
    "    transforms.Resize(16), \n",
    "    lambda x: transforms.functional.rotate(x, 180)\n",
    "])\n",
    "custom_test = datasets.ImageFolder('custom_data/', transform=tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, lab = custom_test[0]\n",
    "print(lab)\n",
    "t1 = img.sum(dim=0, keepdim=True)\n",
    "t1 = torch.where(t1 < 2, 1., 0.)\n",
    "print(t1.shape)\n",
    "plt.imshow(t1.squeeze(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(t1.to(device))\n",
    "print(torch.argmax(pred.cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=16, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=16, out_features=5, bias=False)\n",
      "    (3): ReLU()\n",
      "  )\n",
      ")\n",
      "[[-0.02995802  0.06048698 -0.00294643 ... -0.03840897  0.01597941\n",
      "   0.02413949]\n",
      " [ 0.03751167  0.00200884  0.03952006 ...  0.01479991 -0.04873639\n",
      "   0.04989079]\n",
      " [ 0.01449017  0.04358295  0.02053194 ...  0.01248768 -0.01249415\n",
      "   0.00027586]\n",
      " ...\n",
      " [-0.00084087  0.00154165 -0.04981082 ... -0.0161896   0.01437821\n",
      "   0.01331058]\n",
      " [-0.03228867 -0.00982332 -0.03382243 ... -0.01653415 -0.00767311\n",
      "  -0.04889172]\n",
      " [ 0.00249162 -0.03335837  0.04968004 ...  0.01078875 -0.04722018\n",
      "  -0.01703155]]\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "print(model.linear_relu_stack[0].weight.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight(m, idx):\n",
    "    return m.linear_relu_stack[idx*2].weight.detach().cpu().numpy()\n",
    "def get_bias(m, idx):\n",
    "    return m.linear_relu_stack[idx*2].bias.detach().cpu().numpy()\n",
    "def to_fixed_point(mat):\n",
    "    return (mat * (2**8)).round().astype(int).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.02995802  0.06048698 -0.00294643 ... -0.03840897  0.01597941\n",
      "   0.02413949]\n",
      " [ 0.03751167  0.00200884  0.03952006 ...  0.01479991 -0.04873639\n",
      "   0.04989079]\n",
      " [ 0.01449017  0.04358295  0.02053194 ...  0.01248768 -0.01249415\n",
      "   0.00027586]\n",
      " ...\n",
      " [-0.00084087  0.00154165 -0.04981082 ... -0.0161896   0.01437821\n",
      "   0.01331058]\n",
      " [-0.03228867 -0.00982332 -0.03382243 ... -0.01653415 -0.00767311\n",
      "  -0.04889172]\n",
      " [ 0.00249162 -0.03335837  0.04968004 ...  0.01078875 -0.04722018\n",
      "  -0.01703155]] [[ 0.00373369 -0.02543828 -0.40735474  0.04673827  0.6668399  -0.43122718\n",
      "  -0.12547009  0.28622603  0.56506217  0.37653485 -0.30774966 -0.41526785\n",
      "   0.52607894 -0.5035312   0.43840837 -0.2418123 ]\n",
      " [-0.38885352  0.07678976 -0.3574415   0.4109099  -0.19175442  0.67773956\n",
      "   0.19241878 -0.09831495 -0.5199163   0.05001806  0.0505731   0.46042225\n",
      "  -0.27061242  0.7671012   0.47709307  0.0838061 ]\n",
      " [ 0.5008487  -0.04207736  0.23432647 -0.29853162  0.56746215 -0.31039646\n",
      "  -0.07153106 -0.04336998  0.0061712   0.40871656  0.23078689  0.3163266\n",
      "  -0.3631019   0.5760086  -0.30534875  0.09225313]\n",
      " [-0.29501727 -0.14228532 -0.43321547 -0.01475831  0.5731547   0.7037265\n",
      "   0.0023899  -0.11944136  0.4990597  -0.42018157 -0.19439518  0.20127104\n",
      "   0.29166964 -0.14100784 -0.22557604  0.2258001 ]\n",
      " [-0.36355603  0.07624948  0.9007993  -0.02694054 -0.666377   -0.16320845\n",
      "   0.02916339  0.05435452  0.60816884  0.00354362 -0.04666859 -0.17444783\n",
      "   0.4368461   0.16459918  0.26523706  0.3333881 ]]\n"
     ]
    }
   ],
   "source": [
    "w0, w2 = get_weight(model, 0), get_weight(model, 1)\n",
    "print(w0, w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.003733687102794647, -0.025438277050852776, -0.4073547422885895, 0.04673827067017555, 0.6668398976325989, -0.4312271773815155, -0.1254700869321823, 0.2862260341644287, 0.5650621652603149, 0.3765348494052887, -0.3077496588230133, -0.41526785492897034, 0.5260789394378662, -0.5035312175750732, 0.43840837478637695, -0.2418123036623001], [-0.388853520154953, 0.07678975909948349, -0.3574415147304535, 0.41090989112854004, -0.19175441563129425, 0.6777395606040955, 0.19241878390312195, -0.09831494837999344, -0.519916296005249, 0.0500180646777153, 0.05057310312986374, 0.46042224764823914, -0.2706124186515808, 0.7671012282371521, 0.47709307074546814, 0.0838061049580574], [0.5008487105369568, -0.042077355086803436, 0.23432646691799164, -0.2985316216945648, 0.567462146282196, -0.3103964626789093, -0.07153106480836868, -0.04336997866630554, 0.006171196699142456, 0.4087165594100952, 0.23078688979148865, 0.3163265883922577, -0.36310189962387085, 0.5760086178779602, -0.3053487539291382, 0.09225313365459442], [-0.295017272233963, -0.1422853171825409, -0.433215469121933, -0.014758314937353134, 0.5731546878814697, 0.7037264704704285, 0.002389895496889949, -0.11944136023521423, 0.4990597069263458, -0.4201815724372864, -0.19439518451690674, 0.20127104222774506, 0.291669636964798, -0.14100784063339233, -0.22557604312896729, 0.22580009698867798], [-0.36355602741241455, 0.07624948024749756, 0.9007992744445801, -0.026940535753965378, -0.6663770079612732, -0.16320845484733582, 0.029163390398025513, 0.05435451865196228, 0.6081688404083252, 0.0035436232574284077, -0.04666859284043312, -0.17444783449172974, 0.4368461072444916, 0.16459918022155762, 0.26523706316947937, 0.333388090133667]]\n"
     ]
    }
   ],
   "source": [
    "print(w2.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, -7, -104, 12, 171, -110, -32, 73, 145, 96, -79, -106, 135, -129, 112, -62], [-100, 20, -92, 105, -49, 174, 49, -25, -133, 13, 13, 118, -69, 196, 122, 21], [128, -11, 60, -76, 145, -79, -18, -11, 2, 105, 59, 81, -93, 147, -78, 24], [-76, -36, -111, -4, 147, 180, 1, -31, 128, -108, -50, 52, 75, -36, -58, 58], [-93, 20, 231, -7, -171, -42, 7, 14, 156, 1, -12, -45, 112, 42, 68, 85]]\n"
     ]
    }
   ],
   "source": [
    "print(to_fixed_point(w2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw0, tb0 = torch.rand(4, 5), torch.rand(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw1, tb1 = torch.rand(4, 4), torch.rand(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw2, tb2 = torch.rand(2, 4), torch.rand(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(to_fixed_point(tw0.numpy()), to_fixed_point(tb0.numpy()))\n",
    "print(to_fixed_point(tw1.numpy()), to_fixed_point(tb1.numpy()))\n",
    "print(to_fixed_point(tw2.numpy()), to_fixed_point(tb2.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx1, tx2 = torch.rand(5,), torch.rand(5,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(to_fixed_point(tx1.numpy()), to_fixed_point(tx2.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import relu\n",
    "ty1 = relu(tw2.matmul(relu(tw1.matmul(relu(tw0.matmul(tx1) + tb0)) + tb1)) + tb2)\n",
    "ty2 = relu(tw2.matmul(relu(tw1.matmul(relu(tw0.matmul(tx2) + tb0)) + tb1)) + tb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(to_fixed_point(ty1.numpy()), to_fixed_point(ty2.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approximate(mat):\n",
    "    tmp = mat * (2**16) \n",
    "    return tmp.round() / (2**16)\n",
    "def approximate_t(mat):\n",
    "    tmp = mat * (2**16) \n",
    "    return tmp.floor() / (2**16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw0r, tb0r = approximate(tw0), approximate(tb0)\n",
    "tw1r, tb1r = approximate(tw1), approximate(tb1)\n",
    "tw2r, tb2r = approximate(tw2), approximate(tb2)\n",
    "tx1r, tx2r = approximate(tx1), approximate(tx2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ty1r = relu(approximate_t(tw2r.matmul(relu(approximate_t(tw1r.matmul(relu(approximate_t(tw0r.matmul(tx1r)) + tb0r))) + tb1r))) + tb2r)\n",
    "ty2r = relu(approximate_t(tw2r.matmul(relu(approximate_t(tw1r.matmul(relu(approximate_t(tw0r.matmul(tx2r)) + tb0r))) + tb1r))) + tb2r)\n",
    "print(to_fixed_point(ty1r.numpy()), to_fixed_point(ty2r.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(to_fixed_point(relu(approximate_t(tw2r.matmul(relu(approximate_t(tw1r.matmul(relu(approximate_t(tw0r.matmul(tx1r)) + tb0r))) + tb1r))) + tb2r).numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
