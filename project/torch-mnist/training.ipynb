{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Subset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = transforms.Compose([ToTensor(), transforms.Resize(16)])\n",
    "mnist_train = datasets.MNIST('mnist_data/', download=True, train=True, transform=tf)\n",
    "mnist_test = datasets.MNIST('mnist_data/', download=True, train=False, transform=tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [0, 1, 2, 3, 4]\n",
    "train_indices = [i for i, label in enumerate(mnist_train.targets) if label in targets]\n",
    "mnist_train_s = Subset(mnist_train, train_indices)\n",
    "test_indices = [i for i, label in enumerate(mnist_test.targets) if label in targets]\n",
    "mnist_test_s = Subset(mnist_test, test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torch.utils.data.DataLoader(mnist_train_s, batch_size=256, shuffle=True)\n",
    "test_set = torch.utils.data.DataLoader(mnist_test_s, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 16\n",
    "hidden_size = 16\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(img_size*img_size, hidden_size, bias=False),\n",
    "            nn.ReLU(),\n",
    "            #nn.Linear(hidden_size, hidden_size),\n",
    "            #nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 5, bias=False),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "#model = torch.load('model_tiny.pth', map_location=torch.device(device))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(tqdm(dataloader)):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #if batch % 100 == 0:\n",
    "        #    loss, current = loss.item(), batch * len(X)\n",
    "        #    print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_set, model, loss_fn, optimizer)\n",
    "    test_loop(test_set, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model_tiny.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, labs = next(iter(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "idx = random.randint(0, len(imgs))\n",
    "print(imgs.shape, labs.shape)\n",
    "plt.imshow(imgs[idx].squeeze())\n",
    "pred = model(imgs[idx].to(device))\n",
    "print(torch.argmax(pred.cpu()), labs[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = transforms.Compose([\n",
    "    ToTensor(), \n",
    "    transforms.CenterCrop(240), \n",
    "    transforms.Resize(16), \n",
    "    lambda x: transforms.functional.rotate(x, 180)\n",
    "])\n",
    "custom_test = datasets.ImageFolder('custom_data/', transform=tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, lab = custom_test[0]\n",
    "print(lab)\n",
    "t1 = img.sum(dim=0, keepdim=True)\n",
    "t1 = torch.where(t1 < 2, 1., 0.)\n",
    "print(t1.shape)\n",
    "plt.imshow(t1.squeeze(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(t1.to(device))\n",
    "print(torch.argmax(pred.cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=16, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=16, out_features=5, bias=False)\n",
      "    (3): ReLU()\n",
      "  )\n",
      ")\n",
      "[[ 0.02651919 -0.03826084  0.03035309 ...  0.01474939  0.02718701\n",
      "   0.01681066]\n",
      " [-0.04441253 -0.03005728 -0.0615841  ...  0.02694984  0.05554254\n",
      "  -0.02049033]\n",
      " [ 0.03967959  0.01237705  0.00526872 ... -0.01183159 -0.01934808\n",
      "  -0.05268165]\n",
      " ...\n",
      " [-0.03036228 -0.00612178  0.02012341 ...  0.05704859  0.03373971\n",
      "   0.03451768]\n",
      " [ 0.03627101  0.02872439  0.06197749 ...  0.00770043 -0.03933718\n",
      "   0.01848188]\n",
      " [-0.05737756  0.04138687  0.03870979 ...  0.05599818  0.00472341\n",
      "  -0.05814941]]\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "print(model.linear_relu_stack[0].weight.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight(m, idx):\n",
    "    return m.linear_relu_stack[idx*2].weight.detach().cpu().numpy()\n",
    "def get_bias(m, idx):\n",
    "    return m.linear_relu_stack[idx*2].bias.detach().cpu().numpy()\n",
    "def to_fixed_point(mat):\n",
    "    return (mat * (2**8)).round().astype(int).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.02651919 -0.03826084  0.03035309 ...  0.01474939  0.02718701\n",
      "   0.01681066]\n",
      " [-0.04441253 -0.03005728 -0.0615841  ...  0.02694984  0.05554254\n",
      "  -0.02049033]\n",
      " [ 0.03967959  0.01237705  0.00526872 ... -0.01183159 -0.01934808\n",
      "  -0.05268165]\n",
      " ...\n",
      " [-0.03036228 -0.00612178  0.02012341 ...  0.05704859  0.03373971\n",
      "   0.03451768]\n",
      " [ 0.03627101  0.02872439  0.06197749 ...  0.00770043 -0.03933718\n",
      "   0.01848188]\n",
      " [-0.05737756  0.04138687  0.03870979 ...  0.05599818  0.00472341\n",
      "  -0.05814941]] [[ 2.30456829e-01  1.97920382e-01 -2.25730255e-01 -2.32890278e-01\n",
      "   1.81446642e-01 -2.81125084e-02  1.71149865e-01  2.72740405e-02\n",
      "  -1.66329488e-01 -1.65744975e-01 -3.69534343e-02 -9.12979525e-03\n",
      "  -1.27709612e-01  2.03615166e-02 -1.75119430e-01  2.34007448e-01]\n",
      " [ 2.65079271e-02  6.62841871e-02  1.03419013e-02  1.11586541e-01\n",
      "   7.60938898e-02 -6.49395436e-02 -1.09402500e-01 -1.55636892e-01\n",
      "  -1.70130491e-01 -2.45154947e-01 -1.06793493e-01 -1.42244205e-01\n",
      "  -2.28730589e-02  7.63704777e-02  4.85608540e-02 -1.72240600e-01]\n",
      " [-1.98527068e-01  3.63089726e-03  2.44212151e-02 -2.20853075e-01\n",
      "  -2.35879372e-04 -2.38096461e-01 -2.12133110e-01 -9.48098600e-02\n",
      "   2.25616887e-01  1.54715613e-01  2.06634924e-01 -2.01642990e-01\n",
      "   1.86323598e-01 -1.26444697e-01 -2.43995488e-01  1.17623836e-01]\n",
      " [-2.14976087e-01 -2.28058517e-01  2.17729047e-01  8.33553299e-02\n",
      "  -1.47252053e-01  8.95436779e-02  2.66278476e-01  6.61971048e-02\n",
      "   1.18323468e-01 -1.02125771e-01 -1.38427004e-01  8.94443169e-02\n",
      "   2.57705182e-01 -9.55385119e-02  1.64170876e-01  5.03576845e-02]\n",
      " [ 3.38361301e-02  1.37616917e-01  2.16894090e-01  2.34168723e-01\n",
      "   3.14671509e-02 -1.87364802e-01 -6.42965138e-02  1.75801869e-02\n",
      "  -1.28199548e-01  2.08149299e-01  2.63694674e-01 -6.79831877e-02\n",
      "  -1.86023936e-02  1.03466310e-01  1.14599124e-01 -1.52190387e-01]]\n"
     ]
    }
   ],
   "source": [
    "w0, w2 = get_weight(model, 0), get_weight(model, 1)\n",
    "print(w0, w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[59, 51, -58, -60, 46, -7, 44, 7, -43, -42, -9, -2, -33, 5, -45, 60], [7, 17, 3, 29, 19, -17, -28, -40, -44, -63, -27, -36, -6, 20, 12, -44], [-51, 1, 6, -57, 0, -61, -54, -24, 58, 40, 53, -52, 48, -32, -62, 30], [-55, -58, 56, 21, -38, 23, 68, 17, 30, -26, -35, 23, 66, -24, 42, 13], [9, 35, 56, 60, 8, -48, -16, 5, -33, 53, 68, -17, -5, 26, 29, -39]]\n"
     ]
    }
   ],
   "source": [
    "print(to_fixed_point(w2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw0, tb0 = torch.rand(4, 5), torch.rand(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw1, tb1 = torch.rand(4, 4), torch.rand(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw2, tb2 = torch.rand(2, 4), torch.rand(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(to_fixed_point(tw0.numpy()), to_fixed_point(tb0.numpy()))\n",
    "print(to_fixed_point(tw1.numpy()), to_fixed_point(tb1.numpy()))\n",
    "print(to_fixed_point(tw2.numpy()), to_fixed_point(tb2.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx1, tx2 = torch.rand(5,), torch.rand(5,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(to_fixed_point(tx1.numpy()), to_fixed_point(tx2.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import relu\n",
    "ty1 = relu(tw2.matmul(relu(tw1.matmul(relu(tw0.matmul(tx1) + tb0)) + tb1)) + tb2)\n",
    "ty2 = relu(tw2.matmul(relu(tw1.matmul(relu(tw0.matmul(tx2) + tb0)) + tb1)) + tb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(to_fixed_point(ty1.numpy()), to_fixed_point(ty2.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approximate(mat):\n",
    "    tmp = mat * (2**16) \n",
    "    return tmp.round() / (2**16)\n",
    "def approximate_t(mat):\n",
    "    tmp = mat * (2**16) \n",
    "    return tmp.floor() / (2**16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw0r, tb0r = approximate(tw0), approximate(tb0)\n",
    "tw1r, tb1r = approximate(tw1), approximate(tb1)\n",
    "tw2r, tb2r = approximate(tw2), approximate(tb2)\n",
    "tx1r, tx2r = approximate(tx1), approximate(tx2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ty1r = relu(approximate_t(tw2r.matmul(relu(approximate_t(tw1r.matmul(relu(approximate_t(tw0r.matmul(tx1r)) + tb0r))) + tb1r))) + tb2r)\n",
    "ty2r = relu(approximate_t(tw2r.matmul(relu(approximate_t(tw1r.matmul(relu(approximate_t(tw0r.matmul(tx2r)) + tb0r))) + tb1r))) + tb2r)\n",
    "print(to_fixed_point(ty1r.numpy()), to_fixed_point(ty2r.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(to_fixed_point(relu(approximate_t(tw2r.matmul(relu(approximate_t(tw1r.matmul(relu(approximate_t(tw0r.matmul(tx1r)) + tb0r))) + tb1r))) + tb2r).numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
