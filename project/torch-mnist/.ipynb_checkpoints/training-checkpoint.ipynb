{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Subset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = transforms.Compose([ToTensor(), transforms.Resize(16)])\n",
    "mnist_train = datasets.MNIST('mnist_data/', download=True, train=True, transform=tf)\n",
    "mnist_test = datasets.MNIST('mnist_data/', download=True, train=False, transform=tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [0, 1, 2, 3, 4]\n",
    "train_indices = [i for i, label in enumerate(mnist_train.targets) if label in targets]\n",
    "mnist_train_s = Subset(mnist_train, train_indices)\n",
    "test_indices = [i for i, label in enumerate(mnist_test.targets) if label in targets]\n",
    "mnist_test_s = Subset(mnist_test, test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torch.utils.data.DataLoader(mnist_train_s, batch_size=256, shuffle=True)\n",
    "test_set = torch.utils.data.DataLoader(mnist_test_s, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 16\n",
    "hidden_size = 16\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(img_size*img_size, hidden_size, bias=False),\n",
    "            nn.ReLU(),\n",
    "            #nn.Linear(hidden_size, hidden_size),\n",
    "            #nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 5, bias=False),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = NeuralNetwork().to(device)\n",
    "model = torch.load('model_tiny.pth', map_location=torch.device(device))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(tqdm(dataloader)):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #if batch % 100 == 0:\n",
    "        #    loss, current = loss.item(), batch * len(X)\n",
    "        #    print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_set, model, loss_fn, optimizer)\n",
    "    test_loop(test_set, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model_tiny.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, labs = next(iter(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 16, 16]) torch.Size([256])\n",
      "tensor(4) tensor(4)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "idx = random.randint(0, len(imgs))\n",
    "print(imgs.shape, labs.shape)\n",
    "plt.imshow(imgs[idx].squeeze())\n",
    "pred = model(imgs[idx].to(device))\n",
    "print(torch.argmax(pred.cpu()), labs[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = transforms.Compose([\n",
    "    ToTensor(), \n",
    "    transforms.CenterCrop(240), \n",
    "    transforms.Resize(16), \n",
    "    lambda x: transforms.functional.rotate(x, 180)\n",
    "])\n",
    "custom_test = datasets.ImageFolder('custom_data/', transform=tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([1, 16, 16])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f56c0b8ea50>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, lab = custom_test[0]\n",
    "print(lab)\n",
    "t1 = img.sum(dim=0, keepdim=True)\n",
    "t1 = torch.where(t1 < 2, 1., 0.)\n",
    "print(t1.shape)\n",
    "plt.imshow(t1.squeeze(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2)\n"
     ]
    }
   ],
   "source": [
    "pred = model(t1.to(device))\n",
    "print(torch.argmax(pred.cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=16, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=16, out_features=5, bias=False)\n",
      "    (3): ReLU()\n",
      "  )\n",
      ")\n",
      "[[-0.02995802  0.06048698 -0.00294643 ... -0.03840897  0.01597941\n",
      "   0.02413949]\n",
      " [ 0.03751167  0.00200884  0.03952006 ...  0.01479991 -0.04873639\n",
      "   0.04989079]\n",
      " [ 0.01449017  0.04358295  0.02053194 ...  0.01248768 -0.01249415\n",
      "   0.00027586]\n",
      " ...\n",
      " [-0.00084087  0.00154165 -0.04981082 ... -0.0161896   0.01437821\n",
      "   0.01331058]\n",
      " [-0.03228867 -0.00982332 -0.03382243 ... -0.01653415 -0.00767311\n",
      "  -0.04889172]\n",
      " [ 0.00249162 -0.03335837  0.04968004 ...  0.01078875 -0.04722018\n",
      "  -0.01703155]]\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "print(model.linear_relu_stack[0].weight.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight(m, idx):\n",
    "    return m.linear_relu_stack[idx*2].weight.detach().cpu().numpy()\n",
    "def get_bias(m, idx):\n",
    "    return m.linear_relu_stack[idx*2].bias.detach().cpu().numpy()\n",
    "def to_fixed_point(mat):\n",
    "    return (mat * (2**8)).round().astype(int).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.02995802  0.06048698 -0.00294643 ... -0.03840897  0.01597941\n",
      "   0.02413949]\n",
      " [ 0.03751167  0.00200884  0.03952006 ...  0.01479991 -0.04873639\n",
      "   0.04989079]\n",
      " [ 0.01449017  0.04358295  0.02053194 ...  0.01248768 -0.01249415\n",
      "   0.00027586]\n",
      " ...\n",
      " [-0.00084087  0.00154165 -0.04981082 ... -0.0161896   0.01437821\n",
      "   0.01331058]\n",
      " [-0.03228867 -0.00982332 -0.03382243 ... -0.01653415 -0.00767311\n",
      "  -0.04889172]\n",
      " [ 0.00249162 -0.03335837  0.04968004 ...  0.01078875 -0.04722018\n",
      "  -0.01703155]] [[ 0.00373369 -0.02543828 -0.40735474  0.04673827  0.6668399  -0.43122718\n",
      "  -0.12547009  0.28622603  0.56506217  0.37653485 -0.30774966 -0.41526785\n",
      "   0.52607894 -0.5035312   0.43840837 -0.2418123 ]\n",
      " [-0.38885352  0.07678976 -0.3574415   0.4109099  -0.19175442  0.67773956\n",
      "   0.19241878 -0.09831495 -0.5199163   0.05001806  0.0505731   0.46042225\n",
      "  -0.27061242  0.7671012   0.47709307  0.0838061 ]\n",
      " [ 0.5008487  -0.04207736  0.23432647 -0.29853162  0.56746215 -0.31039646\n",
      "  -0.07153106 -0.04336998  0.0061712   0.40871656  0.23078689  0.3163266\n",
      "  -0.3631019   0.5760086  -0.30534875  0.09225313]\n",
      " [-0.29501727 -0.14228532 -0.43321547 -0.01475831  0.5731547   0.7037265\n",
      "   0.0023899  -0.11944136  0.4990597  -0.42018157 -0.19439518  0.20127104\n",
      "   0.29166964 -0.14100784 -0.22557604  0.2258001 ]\n",
      " [-0.36355603  0.07624948  0.9007993  -0.02694054 -0.666377   -0.16320845\n",
      "   0.02916339  0.05435452  0.60816884  0.00354362 -0.04666859 -0.17444783\n",
      "   0.4368461   0.16459918  0.26523706  0.3333881 ]]\n"
     ]
    }
   ],
   "source": [
    "w0, w2 = get_weight(model, 0), get_weight(model, 1)\n",
    "print(w0, w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, -7, -104, 12, 171, -110, -32, 73, 145, 96, -79, -106, 135, -129, 112, -62], [-100, 20, -92, 105, -49, 174, 49, -25, -133, 13, 13, 118, -69, 196, 122, 21], [128, -11, 60, -76, 145, -79, -18, -11, 2, 105, 59, 81, -93, 147, -78, 24], [-76, -36, -111, -4, 147, 180, 1, -31, 128, -108, -50, 52, 75, -36, -58, 58], [-93, 20, 231, -7, -171, -42, 7, 14, 156, 1, -12, -45, 112, 42, 68, 85]]\n"
     ]
    }
   ],
   "source": [
    "print(to_fixed_point(w2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw0, tb0 = torch.rand(4, 5), torch.rand(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw1, tb1 = torch.rand(4, 4), torch.rand(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw2, tb2 = torch.rand(2, 4), torch.rand(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(to_fixed_point(tw0.numpy()), to_fixed_point(tb0.numpy()))\n",
    "print(to_fixed_point(tw1.numpy()), to_fixed_point(tb1.numpy()))\n",
    "print(to_fixed_point(tw2.numpy()), to_fixed_point(tb2.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx1, tx2 = torch.rand(5,), torch.rand(5,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(to_fixed_point(tx1.numpy()), to_fixed_point(tx2.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import relu\n",
    "ty1 = relu(tw2.matmul(relu(tw1.matmul(relu(tw0.matmul(tx1) + tb0)) + tb1)) + tb2)\n",
    "ty2 = relu(tw2.matmul(relu(tw1.matmul(relu(tw0.matmul(tx2) + tb0)) + tb1)) + tb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(to_fixed_point(ty1.numpy()), to_fixed_point(ty2.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approximate(mat):\n",
    "    tmp = mat * (2**16) \n",
    "    return tmp.round() / (2**16)\n",
    "def approximate_t(mat):\n",
    "    tmp = mat * (2**16) \n",
    "    return tmp.floor() / (2**16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw0r, tb0r = approximate(tw0), approximate(tb0)\n",
    "tw1r, tb1r = approximate(tw1), approximate(tb1)\n",
    "tw2r, tb2r = approximate(tw2), approximate(tb2)\n",
    "tx1r, tx2r = approximate(tx1), approximate(tx2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ty1r = relu(approximate_t(tw2r.matmul(relu(approximate_t(tw1r.matmul(relu(approximate_t(tw0r.matmul(tx1r)) + tb0r))) + tb1r))) + tb2r)\n",
    "ty2r = relu(approximate_t(tw2r.matmul(relu(approximate_t(tw1r.matmul(relu(approximate_t(tw0r.matmul(tx2r)) + tb0r))) + tb1r))) + tb2r)\n",
    "print(to_fixed_point(ty1r.numpy()), to_fixed_point(ty2r.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(to_fixed_point(relu(approximate_t(tw2r.matmul(relu(approximate_t(tw1r.matmul(relu(approximate_t(tw0r.matmul(tx1r)) + tb0r))) + tb1r))) + tb2r).numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
